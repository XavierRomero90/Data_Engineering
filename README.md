# Data_Engineering
Top-Level Data Engineering Projects

Español 
Preceso ETL en el que consta de los siguientes pasos:
- Creacion de instacia EC2 de aws.
- Instalacion de todo el software necesario en instacia EC2 ubuntu t3-medium con todos los accesso necesarios.
- Creacion de dag en Apache Airflow con sus debidos endpoints.
- Obtencion de credenciales para generar los api call en la pagina web: https://openweathermap.org/current
- Gneracion de todo el codigo para el proceso ETL en lenguaje de programación Python.
- Generación de DAG final en Airflow en donde se detalla que el proceso ha sido exitiso.
- Se generan credenciales aws para guardar el dataset final en el lago de datos de aws, esto es S3 en su respectivo
  bucket nombrado para el efecto: "cuenca-etl".

English Version:
- Creation of EC2 AWS instance.
- Installation of all the necessary software packages and add-ons on an EC2 Ubuntu t3-medium instance with all the required access.
- Setup of dag in Apache Airflow with its due endpoints.
- Obtaining credentials to generate the API calls on the website: https://openweathermap.org/current
- Generation of all the code for the ETL process in the Python programming language.
- Implementation of final DAG in Airflow detailing the success of the process.
- AWS credentials are generated to save the final dataset in the AWS data lake (S3) in its respective
  bucket named after the corresponding project, that is: "cuenca-etl".

